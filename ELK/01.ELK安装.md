# ELK安装

yum install -y lrzsz net-tools sysstat telnet wget lsof
sed -i "s/SELINUX=enforcing/SELINUX=disabled/" /etc/selinux/config
setenforce 0

```shell
wget -c https://artifacts.elastic.co/downloads/logstash/logstash-6.0.1.rpm
wget -c https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.0.1.rpm
wget -c https://artifacts.elastic.co/downloads/kibana/kibana-6.0.1-x86_64.rpm
```
~~wget -c https://artifacts.elastic.co/downloads/filebeat/filebeat-6.0.1.rpm~~

```shell  
echo "vm.max_map_count=262144" >> /etc/sysctl.conf   
echo "fs.file-max = 1000000" >> /etc/sysctl.conf   
echo "vm.swappiness=0" >> /etc/sysctl.conf   
sysctl -p


vim /etc/security/limits.conf
添加：
echo "* soft nofile 655350 " >> /etc/security/limits.conf
echo "* hard nofile 655350 " >> /etc/security/limits.conf
echo "elasticsearch soft memlock unlimited " >> /etc/security/limits.conf
echo "elasticsearch hard memlock unlimited" >> /etc/security/limits.conf

rpm -ivh jdk-8u152-linux-x64.rpm
rpm -ivh logstash-6.0.1.rpm
rpm -ivh elasticsearch-6.0.1.rpm
rpm -ivh kibana-6.0.1-x86_64.rpm


systemctl enable logstash
systemctl start logstash
systemctl status logstash

sudo systemctl daemon-reload
sudo systemctl enable elasticsearch.service
systemctl start elasticsearch.service
systemctl status elasticsearch.service



systemctl enable kibana
systemctl start kibana
systemctl status kibana





rpm -qc elasticsearch
  /etc/elasticsearch/elasticsearch.yml
  /etc/elasticsearch/jvm.options
  /etc/elasticsearch/log4j2.properties
  /etc/init.d/elasticsearch
  /etc/sysconfig/elasticsearch
  /usr/lib/sysctl.d/elasticsearch.conf
  /usr/lib/systemd/system/elasticsearch.service


vi /etc/elasticsearch/elasticsearch.yml
network.host: 0.0.0.0



cluster.name: qksystem
node.name: qk-node1
node.master: true #master和node节点互斥
node.data: fase   #master和node节点互斥
action.auto_create_index:true  # 自动创建索引
path.data: /var/lib/elasticseach/data
path.logs: /var/log/elasticsearch
bootstrap.memory_lock: true #锁住内存
network.host: 0.0.0.0 #绑定的IP地址
http:port 9200 #API交互端口
transport.host: 10.81.84.73 #设置传输交互IP地址，为本机
transport.tcp.port: 9300 #交互端口
discovery.zen.ping.unicast.hosts: ["x.x.x.x:9300","x.x.x.x:9300","x.x.x.x:9300"] #防止脑裂，固定好集群的节点
discovery.zen.minimum_master_nodes: 1 #保证集群中的节点可以知道其他N个又master资格的节点，默认为1，大集群可以设置大一点2-4
discovery.zen.fd.ping_timeout: 30s #节点等待响应多久后超时，节点探测
# 设置head插件可以启用
http.cors.enabled: true
http.cors.allow-origin: "*"    


sed -i "s/#cluster.name: my-application/cluster.name: qksystem/" /etc/elasticsearch/elasticsearch.yml
sed -i "s/#node.name: node-1/node.name: qk-node1/" /etc/elasticsearch/elasticsearch.yml
sed -i "s/#bootstrap.memory_lock: true/bootstrap.memory_lock: true/" /etc/elasticsearch/elasticsearch.yml
sed -i "s/#network.host: 192.168.0.1/network.host: 0.0.0.0/" /etc/elasticsearch/elasticsearch.yml
sed -i "s/#http.port: 9200/http.port: 9200/" /etc/elasticsearch/elasticsearch.yml
echo "node.master: true" >> /etc/elasticsearch/elasticsearch.yml
echo "node.data: false" >> /etc/elasticsearch/elasticsearch.yml
echo "action.auto_create_index: true" >> /etc/elasticsearch/elasticsearch.yml
echo "http.cors.enabled: true" >> /etc/elasticsearch/elasticsearch.yml
echo "http.cors.allow-origin: \"*\"" >> /etc/elasticsearch/elasticsearch.yml
echo "transport.host: 10.81.84.73" >> /etc/elasticsearch/elasticsearch.yml
echo "transport.tcp.port: 9300" >> /etc/elasticsearch/elasticsearch.yml

systemctl restart elasticsearch





节点健康状态
http://119.254.101.219:9200/_cluster/health?pretty
集群健康状态
http://119.254.101.219:9200/_cat/health?v
检查集群的节点
http://119.254.101.219:9200/_cat/nodes?v
所有的Index
http://119.254.101.219:9200/_cat/indices?v

rpm -qc logstash
  /etc/logstash/jvm.options
  /etc/logstash/log4j2.properties
  /etc/logstash/logstash.yml
  /etc/logstash/startup.options


vi /etc/kibana/kibana.yml
  server.port: 5601
  server.host: "0.0.0.0"
  elasticsearch.url: "http://127.0.0.1:9200"

sed -i "s/#server.port: 5601/server.port: 5601/" /etc/kibana/kibana.yml
sed -i "s/#server.host: \"localhost\"/server.host: \"0.0.0.0\"/" /etc/kibana/kibana.yml
sed -i "s/#elasticsearch.url: \"http:\/\/localhost:9200\"/elasticsearch.url: \"http:\/\/127.0.0.1:9200\"/" /etc/kibana/kibana.yml

systemctl restart kibana


cd /etc/logstash/conf.d/
vi qkapp.conf
input {  
  tcp {  
    mode => "server"
    port => 9250
    codec => json {
          charset => "UTF-8"
      }  
  }  
}  
filter {
    json {
      source=>"message"
      target=>"content"
      #target => "doc"
      #remove_field => ["message"]
    }
}
output {  
  elasticsearch {  
    action => "index"          #The operation on ES  
    hosts  => "127.0.0.1:9200"   #ElasticSearch host, can be array.        
    index  => "qkapplog"         #The index to write data to.  
  }  
}  

/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/qkapp.conf

firewall-cmd --zone=public --add-port=9200/tcp --permanent
firewall-cmd --zone=public --add-port=9300/tcp --permanent
firewall-cmd --zone=public --add-port=5601/tcp --permanent
firewall-cmd --zone=public --add-port=9250/tcp --permanent
firewall-cmd --reload
```
